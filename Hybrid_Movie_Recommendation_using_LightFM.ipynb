{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid Movie Recommendation using LightFM  ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalinagel12/movieRecommender/blob/master/Hybrid_Movie_Recommendation_using_LightFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kDn_lVxg3Z2G"
      },
      "source": [
        "# Importing a library that is not in Colaboratory\n",
        "\n",
        "To import a library that's not in Colaboratory by default, you can use `!pip install` or `!apt-get install`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQ18Kd5F3uKe",
        "colab": {}
      },
      "source": [
        "!pip install -q matplotlib-venn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "__3eqm3q3sr-",
        "outputId": "f5bbdef9-8318-4dce-e929-8fc11ce22d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "(Reading database ... 130911 files and directories currently installed.)\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iDu3Slhq2zyh"
      },
      "source": [
        "# Upgrading TensorFlow\n",
        "\n",
        "[TensorFlow](https://www.tensorflow.org/) is available by default but you can switch which version you're using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6km1lWMF2kAm",
        "outputId": "5d674836-ff5b-453d-dc37-5ecb033e9383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2094
        }
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# For a specific version:\n",
        "!pip install tensorflow==1.2\n",
        "\n",
        "# For the latest nightly build:\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.13.1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: keras-preprocessing, grpcio, six, astor, numpy, tensorboard, keras-applications, termcolor, gast, wheel, protobuf, absl-py, tensorflow-estimator\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.4)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0MB 1.6MB/s \n",
            "\u001b[?25hCollecting html5lib==0.9999999 (from tensorflow==1.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.6MB/s \n",
            "\u001b[?25hCollecting markdown==2.2.0 (from tensorflow==1.2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.16.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.33.4)\n",
            "Collecting backports.weakref==1.0rc1 (from tensorflow==1.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Collecting bleach==1.5.0 (from tensorflow==1.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (41.0.1)\n",
            "Building wheels for collected packages: html5lib, markdown\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "Successfully built html5lib markdown\n",
            "\u001b[31mERROR: tensorboard 1.13.1 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: html5lib, markdown, backports.weakref, bleach, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: Markdown 3.1.1\n",
            "    Uninstalling Markdown-3.1.1:\n",
            "      Successfully uninstalled Markdown-3.1.1\n",
            "  Found existing installation: backports.weakref 1.0.post1\n",
            "    Uninstalling backports.weakref-1.0.post1:\n",
            "      Successfully uninstalled backports.weakref-1.0.post1\n",
            "  Found existing installation: bleach 3.1.0\n",
            "    Uninstalling bleach-3.1.0:\n",
            "      Successfully uninstalled bleach-3.1.0\n",
            "  Found existing installation: tensorflow 1.13.1\n",
            "    Uninstalling tensorflow-1.13.1:\n",
            "      Successfully uninstalled tensorflow-1.13.1\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/a1/55730f8f1cad52343cd339b51350f978515e327014d512e95acfa3281e14/tf_nightly-1.14.1.dev20190530-cp36-cp36m-manylinux1_x86_64.whl (109.6MB)\n",
            "\u001b[K     |████████████████████████████████| 109.6MB 16.4MB/s \n",
            "\u001b[?25hCollecting wrapt>=1.11.1 (from tf-nightly)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
            "Collecting google-pasta>=0.1.6 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 23.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.33.4)\n",
            "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/00/5958380d6d0c848d24d8a363064a9db56415a1b5fab7de1d567994395261/tb_nightly-1.14.0a20190530-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.16.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.7.1)\n",
            "Collecting tf-estimator-nightly (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/8d/113cb87e29b550b893843c71f9ac9b8a12a7c2348b501fa7c1ec5909bd2a/tf_estimator_nightly-1.14.0.dev2019052901-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.0.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly) (0.15.4)\n",
            "Collecting markdown>=2.6.8 (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly) (2.8.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
            "Successfully built wrapt\n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.2.0 has requirement markdown==2.2.0, but you'll have markdown 3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: wrapt, google-pasta, markdown, tb-nightly, tf-estimator-nightly, tf-nightly\n",
            "  Found existing installation: wrapt 1.10.11\n",
            "    Uninstalling wrapt-1.10.11:\n",
            "      Successfully uninstalled wrapt-1.10.11\n",
            "  Found existing installation: Markdown 2.2.0\n",
            "    Uninstalling Markdown-2.2.0:\n",
            "      Successfully uninstalled Markdown-2.2.0\n",
            "Successfully installed google-pasta-0.1.7 markdown-3.1.1 tb-nightly-1.14.0a20190530 tf-estimator-nightly-1.14.0.dev2019052901 tf-nightly-1.14.1.dev20190530 wrapt-1.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "apoRbfWsRZ7S"
      },
      "source": [
        "# Install 7zip reader [libarchive](https://pypi.python.org/pypi/libarchive) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_j7nNbKRmhx",
        "outputId": "f3802c21-f6c1-4c85-caa1-7803d153f343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -q -U libarchive\n",
        "import libarchive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 130916 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.2.2-3.1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.2.2-3.1ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up libarchive-dev:amd64 (3.2.2-3.1ubuntu0.3) ...\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PeaSX9KXR58J"
      },
      "source": [
        "# Install GraphViz & [PyDot](https://pypi.python.org/pypi/pydot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9llCG2wSRDx",
        "colab": {}
      },
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "import pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tlh1MKxGrKFO"
      },
      "source": [
        "# Install [cartopy](http://scitools.org.uk/cartopy/docs/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zq68DSY2rP2W",
        "outputId": "81ae6fe0-ed13-4852-f938-2a73b98d05ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "!apt-get -qq install python-cartopy python3-cartopy\n",
        "import cartopy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-pkg-resources.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 130972 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-pyshp.\n",
            "Preparing to unpack .../1-python-pyshp_1.2.12+ds-1_all.deb ...\n",
            "Unpacking python-pyshp (1.2.12+ds-1) ...\n",
            "Selecting previously unselected package python-shapely.\n",
            "Preparing to unpack .../2-python-shapely_1.6.4-1_amd64.deb ...\n",
            "Unpacking python-shapely (1.6.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cartopy:amd64.\n",
            "Preparing to unpack .../4-python-cartopy_0.14.2+dfsg1-2build3_amd64.deb ...\n",
            "Unpacking python-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../5-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-pyshp.\n",
            "Preparing to unpack .../6-python3-pyshp_1.2.12+ds-1_all.deb ...\n",
            "Unpacking python3-pyshp (1.2.12+ds-1) ...\n",
            "Selecting previously unselected package python3-shapely.\n",
            "Preparing to unpack .../7-python3-shapely_1.6.4-1_amd64.deb ...\n",
            "Unpacking python3-shapely (1.6.4-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../8-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cartopy:amd64.\n",
            "Preparing to unpack .../9-python3-cartopy_0.14.2+dfsg1-2build3_amd64.deb ...\n",
            "Unpacking python3-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n",
            "Setting up python-shapely (1.6.4-1) ...\n",
            "Setting up python-pyshp (1.2.12+ds-1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-shapely (1.6.4-1) ...\n",
            "Setting up python3-pyshp (1.2.12+ds-1) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python3-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n",
            "Setting up python-cartopy:amd64 (0.14.2+dfsg1-2build3) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-waVv2vfThCX",
        "colab_type": "code",
        "outputId": "ff26df1e-3954-4e4b-c592-98433fbb5127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install lightfm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lightfm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/8e/5485ac5a8616abe1c673d1e033e2f232b4319ab95424b42499fabff2257f/lightfm-1.15.tar.gz (302kB)\n",
            "\r\u001b[K     |█                               | 10kB 10.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.16.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from lightfm) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from lightfm) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/bb/ac/188385a5da6627956be5d9663928483b36da576149ab5b8f79\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9u1itAoSw-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from lightfm.datasets import fetch_movielens\n",
        "from lightfm import LightFM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52PnII2DSyM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = fetch_movielens(min_rating=4.0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9KFXGwjTc8z",
        "colab_type": "code",
        "outputId": "563779d4-1cb5-420d-85b4-b744d5adccda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(repr(data['train']))\n",
        "print(repr(data['test']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 49906 stored elements in COOrdinate format>\n",
            "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
            "\twith 5469 stored elements in COOrdinate format>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2nj4JBKT7Ge",
        "colab_type": "code",
        "outputId": "47ffea04-08b7-44dc-af14-cb05a7aaf4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#create model\n",
        "model = LightFM(loss='warp')\n",
        "#train model\n",
        "model.fit(data['train'], epochs=30, num_threads=2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f0f5ba3de80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDSsvIQnV0DU",
        "colab_type": "code",
        "outputId": "49bf0fff-a92a-4b7f-f06b-df75bf8ea052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'item_feature_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'item_features': <1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
              " \twith 1682 stored elements in Compressed Sparse Row format>,\n",
              " 'item_labels': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'test': <943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
              " \twith 5469 stored elements in COOrdinate format>,\n",
              " 'train': <943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
              " \twith 49906 stored elements in COOrdinate format>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZVnCcM-WKE_",
        "colab_type": "code",
        "outputId": "dc2a6d78-90e3-4136-c3cb-7a9d68df28d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f0f5ba3de80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz2WGfDWWMtF",
        "colab_type": "code",
        "outputId": "bcce9d7e-10be-4584-e792-dd039cf8829f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-50dd2841b54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'user_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXJ8FlpDT_kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_recommendation(model, data, user_ids):\n",
        "\n",
        "    #number of users and movies in training data\n",
        "    n_users, n_items = data['train'].shape\n",
        "\n",
        "    #generate recommendations for each user we input\n",
        "    for user_id in user_ids:\n",
        "\n",
        "        #movies they already like\n",
        "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
        "\n",
        "        #movies our model predicts they will like\n",
        "        scores = model.predict(user_id, np.arange(n_items))\n",
        "        #rank them in order of most liked to least\n",
        "        top_items = data['item_labels'][np.argsort(-scores)]\n",
        "\n",
        "        #print out the results\n",
        "        print(\"User %s\" % user_id)\n",
        "        print(\"     Known positives:\")\n",
        "\n",
        "        for x in known_positives[:3]:\n",
        "            print(\"        %s\" % x)\n",
        "\n",
        "        print(\"     Recommended:\")\n",
        "\n",
        "        for x in top_items[:3]:\n",
        "            print(\"        %s\" % x)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsF5wXYnUDdk",
        "colab_type": "code",
        "outputId": "f6fd6bd9-5747-4f4d-aca5-f7d718b93a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "sample_recommendation(model, data, [3, 25, 450,1,20])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User 3\n",
            "     Known positives:\n",
            "        Seven (Se7en) (1995)\n",
            "        Contact (1997)\n",
            "        Starship Troopers (1997)\n",
            "     Recommended:\n",
            "        Contact (1997)\n",
            "        Scream (1996)\n",
            "        Chasing Amy (1997)\n",
            "User 25\n",
            "     Known positives:\n",
            "        Dead Man Walking (1995)\n",
            "        Star Wars (1977)\n",
            "        Fargo (1996)\n",
            "     Recommended:\n",
            "        Fargo (1996)\n",
            "        English Patient, The (1996)\n",
            "        Contact (1997)\n",
            "User 450\n",
            "     Known positives:\n",
            "        Contact (1997)\n",
            "        George of the Jungle (1997)\n",
            "        Event Horizon (1997)\n",
            "     Recommended:\n",
            "        Devil's Advocate, The (1997)\n",
            "        Air Force One (1997)\n",
            "        Conspiracy Theory (1997)\n",
            "User 1\n",
            "     Known positives:\n",
            "        Toy Story (1995)\n",
            "        Postino, Il (1994)\n",
            "        Birdcage, The (1996)\n",
            "     Recommended:\n",
            "        English Patient, The (1996)\n",
            "        Fargo (1996)\n",
            "        Secrets & Lies (1996)\n",
            "User 20\n",
            "     Known positives:\n",
            "        Toy Story (1995)\n",
            "        Twelve Monkeys (1995)\n",
            "        Dead Man Walking (1995)\n",
            "     Recommended:\n",
            "        Scream (1996)\n",
            "        Chasing Amy (1997)\n",
            "        Heat (1995)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "staVYBf6UF-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}